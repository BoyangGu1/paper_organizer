{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "from typing import Union, Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Paper():\n",
    "\n",
    "    def __init__(self, \n",
    "                 paper_loc: str, \n",
    "                 datasave_loc: str, \n",
    "                 notes_loc: str) -> None:\n",
    "        self.paper_loc = paper_loc\n",
    "        self.datasave_loc = datasave_loc\n",
    "        self.notes_loc = notes_loc\n",
    "        self.name = None # paper title\n",
    "        self.bibtex = None\n",
    "        self.category = None\n",
    "        self.update_notes()\n",
    "        self.keywords = []\n",
    "        self.active_attr_list = [] # without notes for simplicity since self.notes contains many notes\n",
    "\n",
    "    def update_notes(self) -> None:\n",
    "        if not os.path.exists(self.notes_loc):\n",
    "            with open(self.notes_loc, 'w'):\n",
    "                pass\n",
    "        with open(self.notes_loc, 'r') as file:\n",
    "            notes = file.read()\n",
    "        notes = notes.split(\"THIS IS A SPLIT LINE\\n\")\n",
    "        self.notes = [note for note in notes if note.strip() != '']\n",
    "\n",
    "    def set_name(self, name: str) -> None:\n",
    "        # paper title\n",
    "        self.name = name\n",
    "        if not 'name' in self.active_attr_list:\n",
    "            self.active_attr_list += ['name']\n",
    "\n",
    "    def set_category(self, cat: str) -> None:\n",
    "        # paper category like survey\n",
    "        safe_cat = ['survey']\n",
    "        if cat in safe_cat:\n",
    "            self.category = cat\n",
    "            if not 'category' in self.active_attr_list:\n",
    "                self.active_attr_list += ['category']\n",
    "        else:\n",
    "            raise ValueError(f'{cat} is not a valid cateogry type. Eg, use survey')\n",
    "\n",
    "    def add_keyword(self, keyword: str) -> None:\n",
    "        if not keyword in self.keywords:\n",
    "            self.keywords.append(keyword)\n",
    "        else:\n",
    "            print(f'No Action: the keyword {keyword} has already been added.')\n",
    "        if not 'keywords' in self.active_attr_list:\n",
    "            self.active_attr_list += ['keywords']\n",
    "\n",
    "    def set_bibtex(self, bibtex: str) -> None:\n",
    "        self.bibtex = bibtex\n",
    "        if not 'bibtex' in self.active_attr_list:\n",
    "            self.active_attr_list += ['bibtex']\n",
    "        # self._bibtex2attr()\n",
    "\n",
    "    def _bibtex2attr(self):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def add_relation(self, another_paper: str, relation: str, note: str) -> None:\n",
    "        with open(self.notes_loc, 'a') as file:\n",
    "            file.write(\"THIS IS A SPLIT LINE\\n\")\n",
    "            file.write(f'RELATION {relation} to {another_paper}: {note}\\n')\n",
    "            file.write(\"THIS IS A SPLIT LINE\\n\")\n",
    "        self.update_notes()\n",
    "    \n",
    "    def data_save(self) -> None:\n",
    "        # replace local csv data with class data, the opposite of data_update\n",
    "        df_data = []\n",
    "        for attr in self.active_attr_list:\n",
    "            if attr == 'keywords':\n",
    "                df_data.append(['keywords', ','.join(self.keywords)])\n",
    "            else:\n",
    "                df_data.append([attr, getattr(self, attr)])\n",
    "        df = pd.DataFrame(df_data, columns=['attribute name', 'attribute data'])\n",
    "        df.to_csv(self.datasave_loc, index=False)\n",
    "    \n",
    "    def data_update(self) -> None:\n",
    "        # replace class data with local csv data, the opposite of data_update\n",
    "        if not os.path.exists(self.datasave_loc):\n",
    "            df = pd.DataFrame([], columns=['attribute name', 'attribute data'])\n",
    "            df.to_csv(self.datasave_loc, index=False)\n",
    "        else:\n",
    "            safe_attr_list = ['name', 'bibtex', 'keywords', 'category']\n",
    "            df = pd.read_csv(self.datasave_loc)\n",
    "            for _, row in df.iterrows():\n",
    "                attr = row['attribute name']\n",
    "                info = row['attribute data']\n",
    "                assert attr in safe_attr_list, f'{attr} is not a legal property for a paper'\n",
    "                if attr == 'keywords':\n",
    "                    self.keywords = info.split(',')\n",
    "                else:\n",
    "                    setattr(self, attr, info)\n",
    "                self.active_attr_list.append(attr)\n",
    "\n",
    "    def show_notes(self) -> None:\n",
    "        self.update_notes()\n",
    "        if self.notes == []:\n",
    "            print('No notes for this paper')\n",
    "        for i, note in enumerate(self.notes):\n",
    "            print(f'{i+1}: {note}')\n",
    "\n",
    "    def show_keywords(self) -> None:\n",
    "        print('Keywords: ' + ','.join(self.keywords))\n",
    "    \n",
    "    def __str__(self) -> str:\n",
    "        info = f\"\"\"\n",
    "                Paper Title: {'[' + self.category + ']' if self.category else ''}{self.name}\\n\\\n",
    "                Paper Location: {self.paper_loc}\\n\n",
    "                \"\"\"\n",
    "        self.update_notes()\n",
    "        if self.notes != []:\n",
    "            info += \"Notes: \" + \"\\n\".join(self.notes)\n",
    "        if self.keywords != []:\n",
    "            info += \"Keywords: \" + ', '.join(self.keywords) + '\\n'\n",
    "        return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CollectionOfPapers():\n",
    "\n",
    "    def __init__(self, collection_loc: str) -> None:\n",
    "        self.paper_no = 0\n",
    "        self.paper_dict = {}\n",
    "\n",
    "        if os.path.exists(collection_loc):\n",
    "            self.collection_loc = collection_loc\n",
    "            self.papers_loc = collection_loc + '\\\\papers\\\\'\n",
    "            self.notes_loc = collection_loc + '\\\\notes\\\\'\n",
    "            self.papers_data_loc = collection_loc + '\\\\data\\\\'\n",
    "        else:\n",
    "            raise ValueError('This path does not exist for CollectionOfPapers to set up.')\n",
    "        \n",
    "        if not os.path.exists(self.papers_loc):\n",
    "            os.makedirs(self.papers_loc)\n",
    "        if not os.path.exists(self.notes_loc):\n",
    "            os.makedirs(self.notes_loc)\n",
    "        if not os.path.exists(self.papers_data_loc):\n",
    "            os.makedirs(self.papers_data_loc)\n",
    "\n",
    "    def add_paper(self, pdf_name: str) -> None:\n",
    "        if not pdf_name.endswith('.pdf'):\n",
    "            pdf_name += '.pdf'\n",
    "        if os.path.exists(self.papers_loc + pdf_name):\n",
    "            self.paper_no += 1\n",
    "            os.rename(self.papers_loc + pdf_name, self.papers_loc + f'{self.paper_no}.pdf')\n",
    "            self.paper_dict[self.paper_no] = Paper(self.papers_loc + f'{self.paper_no}.pdf', \n",
    "                                                   self.papers_data_loc + f'{self.paper_no}.csv',\n",
    "                                                   self.notes_loc + f'{self.paper_no}.txt')\n",
    "            print(f'Added pdf with name {pdf_name} into the CollectionOfPapers dataset. Paper ID {self.paper_no}')\n",
    "        else:\n",
    "            raise ValueError(f'This pdf does not exist under the path {self.papers_loc}.')\n",
    "        \n",
    "    def auto_add_papers(self, summary: bool = False) -> None:\n",
    "        pdf_names = [os.path.basename(file_path) for file_path in glob.glob(os.path.join(self.papers_loc, '*'))]\n",
    "\n",
    "        while (str(self.paper_no + 1) + '.pdf') in pdf_names:\n",
    "            pdf_names.remove(str(self.paper_no + 1) + '.pdf')\n",
    "            self.paper_no += 1\n",
    "            if not f'{self.paper_no}' in self.paper_dict:\n",
    "                self.paper_dict[self.paper_no] = Paper(self.papers_loc + f'{self.paper_no}.pdf', \n",
    "                                                    self.papers_data_loc + f'{self.paper_no}.csv',\n",
    "                                                    self.notes_loc + f'{self.paper_no}.txt')\n",
    "                if summary:\n",
    "                    print(f'Added pdf with name {self.paper_no + 1}.pdf into the CollectionOfPapers dataset.')\n",
    "            \n",
    "        for pdf_name in pdf_names:\n",
    "            if pdf_name.endswith('.pdf'):\n",
    "                self.paper_no += 1\n",
    "                os.rename(self.papers_loc + pdf_name, self.papers_loc + f'{self.paper_no}.pdf')\n",
    "                self.paper_dict[self.paper_no] = Paper(self.papers_loc + f'{self.paper_no}.pdf', \n",
    "                                                        self.papers_data_loc + f'{self.paper_no}.csv',\n",
    "                                                        self.notes_loc + f'{self.paper_no}.txt')\n",
    "                if summary:\n",
    "                    print(f'Added pdf with name {pdf_name} into the CollectionOfPapers dataset.')\n",
    "\n",
    "    def add_category(self, indices: Union[list[int], int], cat: str):\n",
    "        if isinstance(indices, int):\n",
    "            paper = self.paper_dict[indices]\n",
    "            paper.set_category(cat)\n",
    "        else:\n",
    "            for index in indices:\n",
    "                paper = self.paper_dict[index]\n",
    "                paper.set_category(cat)\n",
    "\n",
    "    def add_relation(self, relations: list[list[int, int, bool, str, str]]):\n",
    "        for paper1_id, paper2_id, mutual, relation_type, note in relations:\n",
    "            paper1: Type[Paper] = self.paper_dict[paper1_id]\n",
    "            paper2: Type[Paper] = self.paper_dict[paper2_id]\n",
    "            paper1.add_relation(paper2_id, relation_type, note)\n",
    "            if mutual:\n",
    "                paper2.add_relation(paper1_id, relation_type, note)\n",
    "            else:\n",
    "                paper2.add_relation(paper1_id, 'BE ' + relation_type, note)\n",
    "\n",
    "    def add_keyword(self, indices: Union[list[int], int], keyword: str):\n",
    "        if isinstance(indices, int):\n",
    "            paper = self.paper_dict[indices]\n",
    "            paper.add_keyword(keyword)\n",
    "        else:\n",
    "            for index in indices:\n",
    "                paper = self.paper_dict[index]\n",
    "                paper.add_keyword(keyword)\n",
    "\n",
    "    def data_save(self):\n",
    "        for paper in self.paper_dict.values():\n",
    "            paper.data_save()\n",
    "\n",
    "    def data_update(self):\n",
    "        for paper in self.paper_dict.values():\n",
    "            paper.data_update()\n",
    "\n",
    "    def __str__(self, full: bool = False) -> str:\n",
    "        info = ''\n",
    "        for i in range(1, self.paper_no + 1):\n",
    "            if full:\n",
    "                info += f'{i}: \\n{self.paper_dict[i].__str__()}'\n",
    "            else:\n",
    "                info += f'{i}: Paper Title: {self.paper_dict[i].name}\\n'\n",
    "            if not 'bibtex' in self.paper_dict[i].active_attr_list:\n",
    "                info += f'Warning: This paper does not have a bibtex.\\n'\n",
    "        return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added pdf with name 2.pdf into the CollectionOfPapers dataset.\n",
      "Added pdf with name 3.pdf into the CollectionOfPapers dataset.\n",
      "Added pdf with name 4.pdf into the CollectionOfPapers dataset.\n",
      "Added pdf with name 5.pdf into the CollectionOfPapers dataset.\n",
      "Added pdf with name 6.pdf into the CollectionOfPapers dataset.\n",
      "Added pdf with name 7.pdf into the CollectionOfPapers dataset.\n",
      "Added pdf with name 8.pdf into the CollectionOfPapers dataset.\n",
      "Added pdf with name 9.pdf into the CollectionOfPapers dataset.\n",
      "Added pdf with name 10.pdf into the CollectionOfPapers dataset.\n",
      "Added pdf with name 11.pdf into the CollectionOfPapers dataset.\n",
      "Added pdf with name 12.pdf into the CollectionOfPapers dataset.\n",
      "Added pdf with name 13.pdf into the CollectionOfPapers dataset.\n",
      "1: Paper Title: Deep reinforcement and transfer learning for abstractive text summarization: A review\n",
      "2: Paper Title: Automatic text summarization: A comprehensive survey\n",
      "3: Paper Title: Automatic summarization of scientific articles: A survey\n",
      "4: Paper Title: Review of automatic text summarization techniques & methods\n",
      "5: Paper Title: Multi-document Summarization via Deep Learning Techniques: A Survey\n",
      "6: Paper Title: A Survey on Multi-modal Summarization\n",
      "7: Paper Title: State-of-the-art approach to extractive text summarization: a comprehensive review\n",
      "8: Paper Title: Abstractive Meeting Summarization: A Survey\n",
      "9: Paper Title: TOP-Rank: A TopicalPostionRank for Extraction and Classification of Keyphrases in Text\n",
      "10: Paper Title: MEDRank: Using graph-based concept ranking to index biomedical texts\n",
      "11: Paper Title: Graph-based biomedical text summarization: An itemset mining and sentence clustering approach\n",
      "12: Paper Title: An Overview of Text Summarization Techniques\n",
      "\n"
     ]
    }
   ],
   "source": [
    "collection_loc = 'c:\\\\Users\\\\sunsh\\\\OneDrive\\\\桌面\\\\MSc_master_project\\\\paper_organizer_database'\n",
    "paper_collection = CollectionOfPapers(collection_loc)\n",
    "paper_collection.auto_add_papers(summary=True)\n",
    "paper_collection.data_update()\n",
    "print(paper_collection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "User guide:\n",
    "\n",
    "`collection.add_paper(pdf_name: str)`\n",
    "\n",
    "`paper.set_name(name: str)`\n",
    "\n",
    "`paper.set_bibtex(bibtex: str)`\n",
    "\n",
    "`paper.data_save()`\n",
    "\n",
    "Note text split by 'THIS IS A SPLIT LINE\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Action: the keyword graph-based has already been added.\n",
      "No Action: the keyword graph-based has already been added.\n",
      "No Action: the keyword graph-based has already been added.\n",
      "No Action: the keyword biomedical has already been added.\n",
      "No Action: the keyword biomedical has already been added.\n",
      "No Action: the keyword SOTA has already been added.\n"
     ]
    }
   ],
   "source": [
    "paper_collection.add_category([1,2,3,4,5,6,7,8,12], 'survey')\n",
    "paper_collection.add_keyword([9,10,11], 'graph-based')\n",
    "paper_collection.add_keyword([10,11], 'biomedical')\n",
    "paper_collection.add_keyword(9, 'SOTA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_collection.add_relation([[7, 9, False, 'cite', 'cite in section 6.3'],\n",
    "                               [7, 10, False, 'cite', 'cite in section 6.3'],\n",
    "                               [7, 11, False, 'cite', 'cite in section 6.3']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: \n",
      "\n",
      "                Paper Title: [survey]Deep reinforcement and transfer learning for abstractive text summarization: A review\n",
      "                Paper Location: c:\\Users\\sunsh\\OneDrive\\桌面\\MSc_master_project\\paper_organizer_database\\papers\\1.pdf\n",
      "\n",
      "                2: \n",
      "\n",
      "                Paper Title: [survey]Automatic text summarization: A comprehensive survey\n",
      "                Paper Location: c:\\Users\\sunsh\\OneDrive\\桌面\\MSc_master_project\\paper_organizer_database\\papers\\2.pdf\n",
      "\n",
      "                3: \n",
      "\n",
      "                Paper Title: [survey]Automatic summarization of scientific articles: A survey\n",
      "                Paper Location: c:\\Users\\sunsh\\OneDrive\\桌面\\MSc_master_project\\paper_organizer_database\\papers\\3.pdf\n",
      "\n",
      "                4: \n",
      "\n",
      "                Paper Title: [survey]Review of automatic text summarization techniques & methods\n",
      "                Paper Location: c:\\Users\\sunsh\\OneDrive\\桌面\\MSc_master_project\\paper_organizer_database\\papers\\4.pdf\n",
      "\n",
      "                5: \n",
      "\n",
      "                Paper Title: [survey]Multi-document Summarization via Deep Learning Techniques: A Survey\n",
      "                Paper Location: c:\\Users\\sunsh\\OneDrive\\桌面\\MSc_master_project\\paper_organizer_database\\papers\\5.pdf\n",
      "\n",
      "                6: \n",
      "\n",
      "                Paper Title: [survey]A Survey on Multi-modal Summarization\n",
      "                Paper Location: c:\\Users\\sunsh\\OneDrive\\桌面\\MSc_master_project\\paper_organizer_database\\papers\\6.pdf\n",
      "\n",
      "                7: \n",
      "\n",
      "                Paper Title: [survey]State-of-the-art approach to extractive text summarization: a comprehensive review\n",
      "                Paper Location: c:\\Users\\sunsh\\OneDrive\\桌面\\MSc_master_project\\paper_organizer_database\\papers\\7.pdf\n",
      "\n",
      "                Notes: This paper discussed extractive text summarization (ETS) with preprocessing, feature extraction, metrics, datasets, and a detailed literature review (section 6).\n",
      "\n",
      "measure/metric -- intrinsic and extrinsic.\n",
      "intrinsic: quality evaluation and content evaluation\n",
      "quality evaluation: coherence and structure, non-redundancy, grammar, reference correct (pronoun)\n",
      "content evaluation: precision, recall, F-score, relative utility (RU), UNFINISHED\n",
      "\n",
      "RELATION cite to 9: cite in section 6.3\n",
      "\n",
      "RELATION cite to 10: cite in section 6.3\n",
      "\n",
      "RELATION cite to 11: cite in section 6.3\n",
      "8: \n",
      "\n",
      "                Paper Title: [survey]Abstractive Meeting Summarization: A Survey\n",
      "                Paper Location: c:\\Users\\sunsh\\OneDrive\\桌面\\MSc_master_project\\paper_organizer_database\\papers\\8.pdf\n",
      "\n",
      "                9: \n",
      "\n",
      "                Paper Title: TOP-Rank: A TopicalPostionRank for Extraction and Classification of Keyphrases in Text\n",
      "                Paper Location: c:\\Users\\sunsh\\OneDrive\\桌面\\MSc_master_project\\paper_organizer_database\\papers\\9.pdf\n",
      "\n",
      "                Notes: RELATION BE cite to 7: cite in section 6.3\n",
      "Keywords: graph-based, SOTA\n",
      "10: \n",
      "\n",
      "                Paper Title: MEDRank: Using graph-based concept ranking to index biomedical texts\n",
      "                Paper Location: c:\\Users\\sunsh\\OneDrive\\桌面\\MSc_master_project\\paper_organizer_database\\papers\\10.pdf\n",
      "\n",
      "                Notes: RELATION BE cite to 7: cite in section 6.3\n",
      "Keywords: graph-based, biomedical\n",
      "11: \n",
      "\n",
      "                Paper Title: Graph-based biomedical text summarization: An itemset mining and sentence clustering approach\n",
      "                Paper Location: c:\\Users\\sunsh\\OneDrive\\桌面\\MSc_master_project\\paper_organizer_database\\papers\\11.pdf\n",
      "\n",
      "                Notes: RELATION BE cite to 7: cite in section 6.3\n",
      "Keywords: graph-based, biomedical\n",
      "12: \n",
      "\n",
      "                Paper Title: [survey]An Overview of Text Summarization Techniques\n",
      "                Paper Location: c:\\Users\\sunsh\\OneDrive\\桌面\\MSc_master_project\\paper_organizer_database\\papers\\12.pdf\n",
      "\n",
      "                \n"
     ]
    }
   ],
   "source": [
    "print(paper_collection.__str__(full=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_collection.data_update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
